[{"figure_path": "2410.18234/tables/table_1_0.html", "caption": "Table 3: Comparison of average acceptance probability across different tasks for K = 2, 4, 8 drafts.", "description": "This table compares the average acceptance probability across different tasks (XSum, Dolly, WMT) for varying numbers of draft models (K=2, 4, 8) using different methods (Optimal, IS, SpecTr, SpecInfer).", "section": "H.1 DRAFT ACCEPTANCE PROBABILITY"}, {"figure_path": "2410.18234/tables/table_9_0.html", "caption": "Table 1: Block efficiency achieved in the Dolly task for different number of draft models.", "description": "Table 1 shows the block efficiency achieved by three different multi-draft speculative sampling methods using 2 to 6 draft models on the Dolly task.", "section": "5.1 IDENTICAL DRAFT MODELS"}, {"figure_path": "2410.18234/tables/table_10_0.html", "caption": "Table 2: Effect of LP Truncation and Alphabet Truncation", "description": "Table 2 shows the effect of LP truncation and alphabet truncation on the block efficiency and token rate improvement over the single-draft baseline.", "section": "4 FASTER IMPORTANCE WEIGHTED SPECULATIVE SAMPLING"}, {"figure_path": "2410.18234/tables/table_37_0.html", "caption": "Table 3: Comparison of average acceptance probability across different tasks for K = 2, 4, 8 drafts.", "description": "Table 3 compares the token-level acceptance probability across different methods for K=2, 4, and 8 drafts on three different tasks.", "section": "H.1 DRAFT ACCEPTANCE PROBABILITY"}, {"figure_path": "2410.18234/tables/table_37_1.html", "caption": "Table 4: Block Efficiency achieved in the Dolly Task with top-k sampling", "description": "Table 4 compares the block efficiencies for different methods using K=2 and K=3 drafts, applying top-k sampling with k=10 and k=5, and using temperature of 1.0 for both models.", "section": "H.2 TOP-k SAMPLING WITH IDENTICAL DRAFT MODELS"}, {"figure_path": "2410.18234/tables/table_38_0.html", "caption": "Table 5: ROUGE-L scores on the XSum task across various decoders and sampling temperatures.", "description": "Table 5 presents ROUGE-L scores on the XSum task for different decoders (IS, single-draft, SpecInfer, SpecTr) and draft model temperatures.", "section": "5.1 IDENTICAL DRAFT MODELS"}, {"figure_path": "2410.18234/tables/table_38_1.html", "caption": "Table 6: BLEU scores on the WMT dataset across various decoders and sampling temperatures.", "description": "Table 6 presents BLEU scores on the WMT dataset for different decoding methods (IS, single-draft speculative decoding, SpecInfer, and SpecTr) across various draft and target model temperatures.", "section": "5.1 IDENTICAL DRAFT MODELS"}, {"figure_path": "2410.18234/tables/table_38_2.html", "caption": "Table 7: ROUGE-L scores on the XSum task across various decoders and sampling temperatures.", "description": "Table 7 compares the ROUGE-L scores for different multi-draft schemes across various decoders and sampling temperatures on the XSum task.", "section": "5.2 NON-IDENTICAL DRAFT MODELS"}, {"figure_path": "2410.18234/tables/table_38_3.html", "caption": "Table 8: BLEU scores on the WMT dataset across various decoders and sampling temperatures.", "description": "Table 8 shows the BLEU scores on the WMT dataset for different multi-draft schemes while varying the temperature of the two draft models.", "section": "5.2 NON-IDENTICAL DRAFT MODELS"}]