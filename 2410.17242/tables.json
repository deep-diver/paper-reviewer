[{"figure_path": "2410.17242/tables/table_7_0.html", "caption": "Table 1: Quantitative comparisons on object-level (left) and scene-level (right) view synthesis. For the object-level comparison, we matched the baseline settings with GS-LRM (Zhang et al., 2024) in both input and rendering under both resolution of 256 (Res-256) and resolution of 512 (Res-512). For the scene-level comparison, we use the same validation dataset used by pixelSplat (Charatan et al., 2024), which has 256 resolution.", "description": "The table presents quantitative comparisons of object-level and scene-level novel view synthesis performance metrics (PSNR, SSIM, LPIPS) for the proposed LVSM model against several state-of-the-art baselines.", "section": "4.3 EVALUATION AGAINST BASELINES"}, {"figure_path": "2410.17242/tables/table_9_0.html", "caption": "Table 1: Quantitative comparisons on object-level (left) and scene-level (right) view synthesis. For the object-level comparison, we matched the baseline settings with GS-LRM (Zhang et al., 2024) in both input and rendering under both resolution of 256 (Res-256) and resolution of 512 (Res-512). For the scene-level comparison, we use the same validation dataset used by pixelSplat (Charatan et al., 2024), which has 256 resolution.", "description": "Table 1 quantitatively compares the performance of the proposed LVSM model against various baselines on object-level and scene-level view synthesis tasks, using PSNR, SSIM, and LPIPS metrics.", "section": "4.3 EVALUATION AGAINST BASELINES"}, {"figure_path": "2410.17242/tables/table_9_1.html", "caption": "Table 1: Quantitative comparisons on object-level (left) and scene-level (right) view synthesis. For the object-level comparison, we matched the baseline settings with GS-LRM (Zhang et al., 2024) in both input and rendering under both resolution of 256 (Res-256) and resolution of 512 (Res-512). For the scene-level comparison, we use the same validation dataset used by pixelSplat (Charatan et al., 2024), which has 256 resolution.", "description": "The table quantitatively compares the performance of the proposed LVSM model with various state-of-the-art methods on object-level and scene-level view synthesis tasks, showing PSNR, SSIM, and LPIPS scores for different resolutions.", "section": "4.3 EVALUATION AGAINST BASELINES"}, {"figure_path": "2410.17242/tables/table_17_0.html", "caption": "Table 1: Quantitative comparisons on object-level (left) and scene-level (right) view synthesis. For the object-level comparison, we matched the baseline settings with GS-LRM (Zhang et al., 2024) in both input and rendering under both resolution of 256 (Res-256) and resolution of 512 (Res-512). For the scene-level comparison, we use the same validation dataset used by pixelSplat (Charatan et al., 2024), which has 256 resolution.", "description": "The table quantitatively compares the proposed LVSM model's performance on object-level and scene-level view synthesis tasks against several state-of-the-art baselines, using PSNR, SSIM, and LPIPS metrics.", "section": "4.3 EVALUATION AGAINST BASELINES"}]