[{"figure_path": "2410.15017/tables/table_7_0.html", "caption": "Table 1: Evaluation of speech reconstruction quality of DM-Codec and comparison with baselines. DM-Codec\u2660 achieves the best performance in WER, WIL, and ViSQOL, highlighting its enhanced content preservation and speech quality, with competitive intelligibility results.", "description": "Table 1 presents a comparison of DM-Codec's speech reconstruction quality against several baseline models using WER, WIL, ViSQOL, and STOI metrics.", "section": "3 EXPERIMENTAL SETUP"}, {"figure_path": "2410.15017/tables/table_8_0.html", "caption": "Table 2: Significance Analysis of DM-Codec (D) compared to baselines EnCodec (E), SpeechTokenizer (S), and FACodec (F). Results reveal DM-Codec consistently achieves significantly better scores in key metrics across all individual samples.  indicates that DM-Codec is significantly better, a denotes dominance, and a X means no significant improvement over the baseline. Avg and Std mean the average and standard deviation of each score.", "description": "Table 2 presents a statistical significance analysis comparing DM-Codec's performance to three baseline speech tokenizers across four key metrics (WER, WIL, ViSQOL, and STOI), showing that DM-Codec significantly outperforms the baselines.", "section": "4 EXPERIMENTAL RESULTS AND DISCUSSION"}, {"figure_path": "2410.15017/tables/table_9_0.html", "caption": "Table 3: Effects of weights on combined representation distillation: Higher LM weight enhances content preservation, leading to lower WER. ASM is the SM weight, ALM is the LM weight.", "description": "Table 3 shows the effects of different weights assigned to LM and SM distillation losses on the word error rate (WER) in speech reconstruction.", "section": "4.3 ABLATION STUDIES"}, {"figure_path": "2410.15017/tables/table_10_0.html", "caption": "Table 4: Analysis of different RVQ layers effect on speech reconstruction. LM-guided distillation on RVQ-1 layer ensures greater content preservation, while SM-guided distillation on RVQ-1:8 layer is more effective at preserving semantic representation. LM-layer and SM-layer indicate the RVQ layer used for respective distillation. \u2663 indicates LM-guided Distillation. \u2660 indicates combined LM and SM-guided Distillation. Bold highlights the best result and underline the second-best result.", "description": "Table 4 shows the performance of DM-Codec speech reconstruction model using different combinations of RVQ layers for LM-guided and combined LM and SM-guided distillation methods.", "section": "4.3 ABLATION STUDIES"}, {"figure_path": "2410.15017/tables/table_11_0.html", "caption": "Table 5: Analysis of representation distillation from different models. BERT can be effectively combined with HuBERT or wav2vec 2.0, however, ELECTRA in LM-guided distillation outperforms BERT. \u2663 indicates LM-guided Distillation. \u2660 indicates combined LM and SM-guided Distillation. Bold highlights the best result and underline the second-best result.", "description": "Table 5 presents an ablation study comparing the performance of DM-Codec using different language models (LM) and speech models (SM) for both LM-guided and combined LM and SM-guided distillation methods.", "section": "4.3 ABLATION STUDIES"}, {"figure_path": "2410.15017/tables/table_12_0.html", "caption": "Table 6: Analysis of different distillation layers representation on speech reconstruction. Average layer provides more comprehensive representations. \u2663 indicates LM-guided Distillation. \u2666 indicates combined LM and SM-guided Distillation. Bold highlights the best result and underline the second-best result.", "description": "Table 6 presents the results of an ablation study evaluating the impact of different distillation layers (average, last, and 9th) on the speech reconstruction quality, using various metrics such as WER, WIL, ViSQOL, and STOI, for both LM-guided and combined LM & SM-guided distillation methods.", "section": "4.3.4 ABLATION STUDY: IMPACT OF DIFFERENT DISTILLATION LAYER(S)"}]