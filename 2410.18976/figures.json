[{"figure_path": "2410.18976/figures/figures_1_0.png", "caption": "Figure 1. The proposed CAMEL-Bench covers eight diverse and challenging domains: multimodal understanding and reasoning, OCR and documents, charts and diagrams, videos, cultural-specific content, medical images, agricultural images, and remote sensing understanding in Arabic. CAMEL-Bench covers 38 sub-domains with over 29K questions carefully curated by native Arabic speakers to rigorously evaluate essential skills desired in Arabic LMMs.", "description": "Figure 1 is a visual representation of the CAMEL-Bench benchmark, illustrating its eight diverse domains and 38 sub-domains, along with the number of questions in each.", "section": "1. Introduction"}, {"figure_path": "2410.18976/figures/figures_2_0.png", "caption": "Figure 1. The proposed CAMEL-Bench covers eight diverse and challenging domains: multimodal understanding and reasoning, OCR and documents, charts and diagrams, videos, cultural-specific content, medical images, agricultural images, and remote sensing understanding in Arabic. CAMEL-Bench covers 38 sub-domains with over 29K questions carefully curated by native Arabic speakers to rigorously evaluate essential skills desired in Arabic LMMs.", "description": "Figure 1 is a diagram showing the eight diverse domains and 38 sub-domains of the CAMEL-Bench, a comprehensive Arabic LMM benchmark.", "section": "1. Introduction"}, {"figure_path": "2410.18976/figures/figures_4_0.png", "caption": "Figure 3. The CAMEL-Bench Filtering and Verification Pipeline consists of two paths: Original Arabic and translated Arabic. For original Arabic (top row), a 20% random sample undergoes manual verification; if errors are below 40%, the data passes; otherwise, the entire sub-category is reviewed. For Translated Arabic (bottom row), We employ Qwen7B model [8] to assess semantic similarity between the original and translated question-answer pairs on fuzzy-basis evaluation. Pairs passing the evaluation proceed, while those that fail undergo manual review. Based on this, data may require Manual Handling for manual re-translation, Refine & Verify for refinement through the model, or Non-Translated Review where the data is re-sent for translation due to the absence of an Arabic version.", "description": "This figure illustrates the two-path pipeline for filtering and verifying data in the CAMEL-Bench, including manual verification for original Arabic data and automated verification with the Qwen7B model for translated Arabic data.", "section": "2. CAMEL-Bench"}, {"figure_path": "2410.18976/figures/figures_5_0.png", "caption": "Figure 4. Qualitative example highlighting different scenarios where different closed-weight models struggle on CAMEL-Bench. The correct response is shown in green, and the incorrect one in the red box.", "description": "Figure 4 presents qualitative examples illustrating challenges faced by different closed-weight models across various tasks within the CAMEL-Bench benchmark.", "section": "3. CAMEL-Bench Benchmark Evaluation"}, {"figure_path": "2410.18976/figures/figures_5_1.png", "caption": "Figure 5. Qualitative example highlighting different scenarios where different open-weight models struggle on CAMEL-Bench. The correct response is shown in green, and the incorrect one in the red box.", "description": "Figure 5 shows examples of open-source LLMs failing to correctly answer questions about cultural identity, medical images, and agricultural images in Arabic.", "section": "3. CAMEL-Bench Benchmark Evaluation"}]