[{"figure_path": "2410.15522/tables/table_2_0.html", "caption": "Table 1: Dataset statistics for M-REWARDBENCH. Number of languages excludes English. For Translation, the languages are Chinese (zh) and German (de).", "description": "Table 1 presents the dataset statistics for M-REWARDBENCH, showing the number of instances and languages for each task category.", "section": "3 M-REWARDBENCH: A Multilingual Benchmark for Evaluating RMs"}, {"figure_path": "2410.15522/tables/table_4_0.html", "caption": "Table 3: Performance drop from RewardBench (English) to M-REWARDBENCH across all categories for the top ten models in M-REWARDBENCH. Icons represent different model types: Classifier-based RMs (), Generative RMs (), and Implicit RMs trained using DPO ().", "description": "Table 3 shows the performance drop of the top ten reward models from English-centric RewardBench to the multilingual M-REWARDBENCH across different categories.", "section": "5 Results"}, {"figure_path": "2410.15522/tables/table_6_0.html", "caption": "Table 4: Top ten reward models based on their performance in the translation task. We source the translation evaluation set from MAPLE (Zhu et al., 2024), where we created EASY and HARD subsets. Icons represent different model types: Classifier-based RMs (), Generative RMs (), and Implicit RMs trained using DPO ().", "description": "Table 4 presents the top ten reward models' performance on the translation task, categorized by model type and performance on easy and hard translation subsets from the MAPLE dataset.", "section": "5.2 Translation Task"}, {"figure_path": "2410.15522/tables/table_13_0.html", "caption": "Table 5: State-of-the-art models evaluated for M-REWARDBENCH.", "description": "Table 5 lists the proprietary and open-source reward models and their sizes used in the M-REWARDBENCH evaluation,  along with their providers and relevant references.", "section": "4 Experiment Details"}, {"figure_path": "2410.15522/tables/table_13_1.html", "caption": "Table 6: The 23 languages in M-REWARDBENCH and their linguistic information. Script, language family, and resource availability are based on Aryabumi et al. (2024). Resource classes are from Joshi et al. (2020).", "description": "Table 6 presents linguistic features of 23 languages included in the M-REWARDBENCH benchmark, including script, family, resource availability, and resource class.", "section": "6.2 Language-specific analysis of RM performances"}, {"figure_path": "2410.15522/tables/table_15_0.html", "caption": "Table 8: Examples where a reward model (RM) disagrees with a native human speaker.", "description": "This table presents examples where reward models' preferences differ from those of native human speakers for Indonesian.", "section": "5 Results"}, {"figure_path": "2410.15522/tables/table_16_0.html", "caption": "Table 10: Performance of all reward models in the translation task. We source the translation evaluation set from MAPLE (Zhu et al., 2024), where we created EASY and HARD subsets. Icons represent different model types: Classifier-based RMs (), Generative RMs (), and Implicit RMs trained using DPO ().", "description": "Table 10 presents the performance of various reward models on the translation task, categorized into easy and hard subsets, using different model types.", "section": "5.2 Translation Task"}]